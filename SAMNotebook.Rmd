---
title: "Stochastic Antecedent Modelling Notebook"
author: "Jon Page"
Last Updated: date()
output:
  html_document:
    df_print: paged
Date: 16/03/2020
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
```


***
# Introduction

This R Markdown Notebook replicates and expands on the work of Ogle et al in 
their 2015 paper.

Ogle, K., Barber, J.J., Barron-Gafford, G.A., Bentley, L.P., Young, J.M., 
Huxman, T.E., Loik, M.E., Tissue, D.T., 2015. 
Quantifying ecological memory in plant and ecosystem processes. 
Ecol Lett 18, 221â€“235. https://doi.org/10.1111/ele.12399

***
# Model Construction

The below code is mostly a re-working of Appendix S2 from Ogle et al. 
The initial step was reproducing the model and results from the paper.
The below section details this.

First we call the model wrapper. The following inputs must be specified:

Datasets - the csv files that provide the ANPP and precip data
Nlag - the number of years for which antecedent precip is assumed to impact NPP
block - the the partitioning of the months into time blocks
Model run parameters - samples, burn, nadapt, nchain, thin
parameters - the parameters in the model that we want to track

```{r}

## Data Initialisation and Model Set Up

rm(list=ls()) # Clear workspace
graphics.off() # This closes all of R's graphics windows.
cat("\f") # Clear console

library(rstudioapi) # Source rstudioapi to set working directory as needed
library(rjags) # Source rjags for Bayesian analysis
library(ggplot2) # Source ggplot2 to plot results
library(gridExtra) # Source gridExtra for better plots
library(DT) # Source DT for datatable
library(dplyr) # Source dplyr for percent_rank

setwd(getwd())

# First import the data (csv files stolen from De Kauwe - data is provided in 
# pdf form in Ogle 2015)

# Import the ANPP and precip partitioned by event data
ANPPandPrecip = read.table("data/dataset2.csv", 
                           header = TRUE, 
                           stringsAsFactors = FALSE)
    # Note that these data are total annual precip (mm) 
    # partitioned into the size of the events that produced the precip:
    # Event1 = received in rain events with <5mm precip
    # Event2 = received in rain events with 5-15mm precip
    # Event3 = received in rain events with 15-30mm precip 
    # Event4 = received in rain events with >30mm precip
    # NPP is in g/m^2. It is actually the forage produced which in Lauenroth 
    # and Sala (1992) is shown to be linearly correlated with ANPP

# Import monthly precip data
Precip = read.table("data/dataset3.csv", 
                    header = TRUE, 
                    stringsAsFactors = FALSE)
    # This covers 91 years
    # Note the precip totals are in inches - the model converts this to mm

# Specify the investigated lag length and the assignment of months to time 
# blocks
# # The number of previous years for which precipitation may affect current NPP
'Nlag'=5 
# Partition months into time blocks e.g. for month 10,11,12 in year 5, 
# group them into time block 38
'block'= matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 
                           16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 26, 
                           27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 31, 32, 32, 
                           32, 33, 33, 33, 34, 34, 34, 35, 35, 35, 36, 36, 36, 
                           37, 37, 37, 38, 38, 38), 
                    nrow=Nlag,ncol=12,byrow = TRUE)

# makes more sense if you visualise it...
block

# Define the parameters for the model operation
# samples to be kept after burn in
samples <- 50000 
# iterations for burn in
burn <- samples * 0.1 
# number of iterations where samplers adapt behaviour to maximise efficiency
nadapt <- 100  
# The number of MCMC chains to run
nchains <- 4 
# thinning rate
# save every thin-th iteration to reduce correlation between 
# consecutive values in the chain
thin <- 10 

# Decide the variables to track
parameters = c('mu','a','weightOrdered','cum.weight','sumD1','weight') 

# Combine the data required for the model
Data = list('Nlag'=Nlag 
            ,'block'= block
            # number of years for which NPP and precip event data are available
            ,'N'=nrow(ANPPandPrecip) 
            # number of years for which monthly precipitation data is available
            ,'Nyrs'=nrow(Precip) 
            # number of time blocks the months are partitioned into
            ,'Nblocks'=max(block) 
            # Monthly precip data
            ,'ppt'=Precip[,-1] 
            # Year ID for NPP
            ,'YearID'=ANPPandPrecip$YearID 
            # Yearly precip event data
            ,'Event'=ANPPandPrecip[,c(4,5,6,7)] 
            # Yearly NPP data - comment this out to obtain the priors
#            ,'NPP'=ANPPandPrecip[,2] 
            )

# Put the model system into a variable
jags <- jags.model('Model.R', data=Data, n.chains=nchains, n.adapt=nadapt) 

```

Now we can run the model. Note, we might not need to if the output files already
exist!!

```{r}
# Generate the MCMC chain (this is basically running the Bayesian analysis)
fit <- coda.samples(jags, n.iter=samples, n.burnin=burn, thin=thin,
                    variable.names=parameters)

# Save the summary of the output as either the prior or posterior
# if NPP data isn't used in the model runs 
# then the output is the prior distributions
 if (length(Data$NPP)==0){ 
      priorSummary = summary(fit)
      save("priorSummary",file="priorSummary.Rdata")
 } else{ 
# NPP data is specified and the output is the posterior distributions
      posteriorSummary = summary(fit)
      save("posteriorSummary",file="posteriorSummary.Rdata")
   }
```

***

Now that we have modelled NPP based on precipitation using Bayesian methods, we
can perform some analysis to confirm that the model has behaved similarly to that
from Ogle et al (it should have done because we used their code!)

We now want to plot figure 2 from Ogle et al for the NPP model to compare our
results to theirs.

```{r}

# Yearly NPP data
NPPobserved=ANPPandPrecip[,2] 
  
# Load the prior and posterior data
load("priorSummary.RData")
load("posteriorSummary.Rdata")

# Create variables for the parameters of interest
priStats = data.frame(priorSummary$statistics)
priQntls = data.frame(priorSummary$quantiles)

priMu = priStats[grep("mu",row.names(priStats)),]
priA = priStats[grep("a",row.names(priStats)),]
priCum.weight = priStats[grep("cum.weight",row.names(priStats)),]
priCum.weightQntls = priQntls[grep("cum.weight",row.names(priQntls)),]
priSumD1 = priStats[grep("sumD1",row.names(priStats)),]
priSumD1Qntls = priQntls[grep("sumD1",row.names(priStats)),]

posStats = data.frame(posteriorSummary$statistics)
posQntls = data.frame(posteriorSummary$quantiles)

posMu = posStats[grep("mu",row.names(posStats)),]
posMuQntls = posQntls[grep("mu",row.names(posStats)),]
posA = posStats[grep("a",row.names(posStats)),]
posAQntls = posQntls[grep("a",row.names(posStats)),]
posCum.weight = posStats[grep("cum.weight",row.names(posStats)),]
posCum.weightQntls = posQntls[grep("cum.weight",row.names(posQntls)),]
posSumD1 = posStats[grep("sumD1",row.names(posStats)),]
posSumD1Qntls = posQntls[grep("sumD1",row.names(posStats)),]


# Create data frames for these variables to facilitate plotting  
posYearlyWeights = data.frame(YearIntoPast = 0:4, 
                              Weight = posSumD1$Mean/sum(posSumD1$Mean), 
                              min = posSumD1Qntls$X2.5./sum(posSumD1$Mean), 
                              max = posSumD1Qntls$X97.5./sum(posSumD1$Mean))
priYearlyWeights = data.frame(YearIntoPast = 0:4, 
                              Weight = priSumD1$Mean/sum(priSumD1$Mean), 
                              min = priSumD1Qntls$X2.5./sum(priSumD1$Mean), 
                              max = priSumD1Qntls$X97.5./sum(priSumD1$Mean))

# Define the corresponding variables for the alpha parameters
aDefinitions=factor(c("PPT","E_0-5","E_5-15","E_15-30","E_>30"),
                    levels=c("PPT","E_0-5","E_5-15","E_15-30","E_>30")) 

posYearlyA = data.frame(aDefinitions, 
                              Covariates = posA$Mean[2:6], 
                              min = posAQntls$X2.5.[2:6], 
                              max = posAQntls$X97.5.[2:6])

# Replicate the plot from Ogle et al 2015 
# for the alpha and yearly weight (page 227)
plot1 <- ggplot(posYearlyWeights,aes(YearIntoPast,
                                     Weight,
                                     ymin = min, 
                                     ymax = max)) + 
      geom_ribbon(data=priYearlyWeights,fill="grey70") +
      geom_line(data=priYearlyWeights) +
      geom_pointrange(data=posYearlyWeights) +
      ylim(0,1)

plot2 <- ggplot(posYearlyWeights,aes(aDefinitions,
                                     Covariates,
                                     ymin = min, 
                                     ymax = max)) + 
      geom_pointrange(data=posYearlyA)
 

grid.arrange(plot1, plot2, nrow = 1)

```

The right hand graph is very similar to Ogle et al - note that the scale of our
y axis is fixed while Ogle et al's changes at y=1.

The left hand graph is very similar to Ogle et al when looking at the posteriors
and also the mean of the priors. However, the credibility intervals (CI) for the
prior do not increase for years 3 and 4 as seen in Ogle et al. 

Ogle's lecture notes state that the 2.5 to 97.5 percentile specifies a CI which
is what is used here. I am unsure why Ogle's CIs expand and ours don't. 

**The above comments are no longer relevant. block was being assigned incorrectly
and since this has been fixed, the above issue is resolved. Our graph matches 
that from the paper, insofar as stochastic methods will allow.**

***

We now plot the observed NPP against our modelled NPP

```{r}
# Plot modelled NPP against observed NPP

NPPobs = data.frame(Year=1:nrow(ANPPandPrecip)+1938,
                    NPP_obs = NPPobserved)
NPPmod = data.frame(Year=1:nrow(ANPPandPrecip)+1938,
                    NPP_mod = posMu[,1],
                    NPP_modmin = posMuQntls[,1],
                    NPP_modmax = posMuQntls[,5])

plot3 <- ggplot(NPPobs) +
  geom_line(data=NPPobs,aes(Year,NPP_obs),color='steelblue',size=2) +
  geom_point(data=NPPobs,aes(Year,NPP_obs),color='steelblue',size=2,na.rm=TRUE) +
  geom_ribbon(data=NPPmod, aes(x=Year, ymin=NPP_modmin, ymax=NPP_modmax), fill="grey70", alpha=0.4) +
  geom_line(data=NPPmod,aes(Year,NPP_mod)) +
  theme_bw() +
  theme(axis.line=element_line(colour = "black"),
    panel.grid.major=element_blank(),
    panel.grid.minor=element_blank(),
    panel.border=element_blank(),
    panel.background=element_blank()) 
  

grid.arrange(plot3)
```


The blue line is the observed NPP. We can see that for the vast majority of years
the observed NPP falls within the CI of our model output. 2 years do not have 
observed NPP which is why we have gaps in the graph.


***

We also replicate figure 4a from Ogle et al. This is the cumulative monthly 
weights.

```{r}
posCum.weightdf = data.frame(monthInPast=1:nrow(posCum.weight),
                    CumulativeWeight = posCum.weight[,1],
                    min = posCum.weightQntls[,1],
                    max = posCum.weightQntls[,5])
priCum.weightdf = data.frame(monthInPast=1:nrow(priCum.weight),
                             CumulativeWeight = priCum.weight[,1],
                             min = priCum.weightQntls[,1],
                             max = priCum.weightQntls[,5])


plot4 <- ggplot(posCum.weightdf) +
      geom_ribbon(data=priCum.weightdf,
                  aes(monthInPast,ymin=min,ymax=max),
                  fill='grey70') +
      coord_cartesian(ylim=c(-0.015,1.015),xlim=c(0,60.5),expand = FALSE) +
      geom_vline(xintercept = 12,color='grey40') +
      geom_vline(xintercept = min(posCum.weightdf$monthInPast[posCum.weightdf$max>=0.9]),
                 color='grey40') +
      geom_vline(xintercept = min(posCum.weightdf$monthInPast[posCum.weightdf$CumulativeWeight>=0.9]),
                 linetype = 'dotted') +
      geom_pointrange(data=posCum.weightdf,aes(monthInPast,
                                          CumulativeWeight,
                                          ymin=min,
                                          ymax=max)) +
      geom_line(data=priCum.weightdf,aes(monthInPast, CumulativeWeight)) +
      geom_hline(yintercept = 0.9,
                 linetype = 'dashed') 


grid.arrange(plot4)
```
We can see how similar our plot is to that of Ogle et al's. 

Of note is that the weight where c = 0.9 is 3 months higher than Ogle's 
(53 vs 50) - therefore our result appears to show that the memory of precipitation
is longer. 
Additional the point at which c = 0.9 is first within the CI of a weight is 48 
for us, while Ogle has this at 42.

Combined with the mismatching priors in Figure 2, this is concerning.

**The above comments are no longer relevant. block was being assigned incorrectly
and since this has been fixed, the above issue is resolved. Our graph matches 
that from the paper, insofar as stochastic methods will allow.**


*** 

A further check is calculating the R^2 value for our model, and compare this to
the value specified by Ogle et al of 0.75 (Table 1).

```{r}
# Calculate value of R2
RSS = sum((posMu[,1]-NPPobserved)^2,na.rm=TRUE)
TSS = sum((NPPobserved-mean(NPPobserved,na.rm=TRUE))^2,na.rm=TRUE)
R2=1-(RSS)/(TSS)
print(R2)
```
As we can see our result is very similar and it is unclear exactly how Ogle et al
calculated their R^2.

***
# Initial investigations

Now that the model is up and running, we can start investigating how changing
the lag or time blocking affects our results.

Two more basic model runs were produced - one with 5 year lag but 60 time blocks
(i.e. each month had a unique weight) and one with a 1 year lag and 12 time 
blocks.

Attempts to plot the results of modelled NPP vs observed are currently struggling
to offset the error bars for clarity...

Therefore, we shall just compare R2 values for now

```{r}
# # Define a function that loads our model output files since all outputs have the
# same variable name
loadRData = function(filename){
      load(filename)
      filename <- get(ls()[grep("Summary",ls())])
      }

# Load the model outputs
priorlag5block38 <- loadRData("priorSummary.Rdata")
posteriorlag5block38 <- loadRData("posteriorSummary.Rdata")
priorlag1block12 <- loadRData("priorSummary_1lag_12blocks.Rdata")
posteriorlag1block12 <- loadRData("posteriorSummary_1lag_12blocks.Rdata")
priorlag5block60 <- loadRData("priorSummary_5lag_60blocks.Rdata")
posteriorlag5block60 <- loadRData("posteriorSummary_5lag_60blocks.Rdata")

# Extract the statistics and the quantiles
Stats = list("pri5.38"=priorlag5block38$statistics,
             "pri5.60"=priorlag5block60$statistics,
             "pri1.12"=priorlag1block12$statistics,
             "pos5.38"=posteriorlag5block38$statistics,
             "pos5.60"=posteriorlag5block60$statistics,
             "pos1.12"=posteriorlag1block12$statistics)

Quantiles = list("pri5.38"=priorlag5block38$quantiles,
                 "pri5.60"=priorlag5block60$quantiles,
                 "pri1.12"=priorlag1block12$quantiles,
                 "pos5.38"=posteriorlag5block38$quantiles,
                 "pos5.60"=posteriorlag5block60$quantiles,
                 "pos1.12"=posteriorlag1block12$quantiles)

# Extract the modelled NPP
NPP5.38 = data.frame("Year"=1:52+1938,
                     "mean"=Stats$pos5.38[grep("mu",row.names(Stats$pos5.38)),1],
                     "min"=Quantiles$pos5.38[grep("mu",row.names(Quantiles$pos5.38)),1],
                     "max"=Quantiles$pos5.38[grep("mu",row.names(Quantiles$pos5.38)),5])
NPP5.60 = data.frame("Year"=1:52+1938,
                     "mean"=Stats$pos5.60[grep("mu",row.names(Stats$pos5.60)),1],
                     "min"=Quantiles$pos5.60[grep("mu",row.names(Quantiles$pos5.60)),1],
                     "max"=Quantiles$pos5.60[grep("mu",row.names(Quantiles$pos5.60)),5])
NPP1.12 = data.frame("Year"=1:52+1938,
                     "mean"=Stats$pos1.12[grep("mu",row.names(Stats$pos1.12)),1],
                     "min"=Quantiles$pos1.12[grep("mu",row.names(Quantiles$pos1.12)),1],
                     "max"=Quantiles$pos1.12[grep("mu",row.names(Quantiles$pos1.12)),5])

#Load ANPP and Precip data and place into dataframe
ANPPandPrecip = read.table("data/dataset2.csv", header = TRUE, 
                           stringsAsFactors = FALSE)
NPPobserved=data.frame("Year" = 1:52+1938,"NPP"=ANPPandPrecip[,2])

RSS5.38 = sum((NPP5.38$mean-NPPobserved$NPP)^2,na.rm=TRUE)
RSS5.60 = sum((NPP5.60$mean-NPPobserved$NPP)^2,na.rm=TRUE)
RSS1.12 = sum((NPP1.12$mean-NPPobserved$NPP)^2,na.rm=TRUE)
TSS = sum((NPPobserved$NPP-mean(NPPobserved$NPP,na.rm=TRUE))^2,na.rm=TRUE)
R2_5.38=1-(RSS5.38)/(TSS)
R2_5.60=1-(RSS5.60)/(TSS)
R2_1.12=1-(RSS1.12)/(TSS)

print(paste("Lag of 5 years and 38 time blocks gives R2 = ", round(R2_5.38,3), sep = ""))
print(paste("Lag of 5 years and 60 time blocks gives R2 = ", round(R2_5.60,3), sep = ""))
print(paste("Lag of 1 year and 12 time blocks gives R2 = ", round(R2_1.12,3), sep = ""))
```

As can be seen, looking only at 1 year gives a substantially worse fit.
Meanwhile, having 60 timeblocks rather than 38 only marginally improves the fit
while dramatically increasing the model runtime. Calculating the DIC would 
probably show a significant preference for the 5.38 run.


*** 

# Creating a function

In an attempt to automate more of the modelling process, I have written a function
that performs the job of the old wrapper script.

I have also written a function that produces Nlag and block if we input the 
number of years that are grouped into each of 1,2,3,6,and 12 monthly weights.
Ideally this function would provide greater flexibility.

I have also written a little script that produces every permutation of assigning
0,1 or 2 years to each of the categories. This would give us 243 different
categorisations to run the model for - this is probably a bit optimistic. 

However, running these and comparing model outputs may well show us something
about lag times. Namely we will have tested lags of length 1 year up to 10 years.
We will also have tested internal weighting of months.


```{r Model run, eval=FALSE, include=TRUE}
# Source the function
source("SAMFunction.R")

# Create a grid of permutations of 5 values either 0, 1 or 2
t = expand.grid(rep(list(0:2), 5))
# Turn this into a matrix for easier extraction
p = matrix(c(t$Var1,t$Var2,t$Var3,t$Var4,t$Var5),nrow = length(t$Var1))
# Print the head of t to visualise this
print(head(t))

# For each row of p but the first (which has a lag of 0), 
# extract the Yj values and run timeblock
for (i in 2:nrow(p)){
  for (j in 1:5){
    assign(paste("Y",j,sep=""), p[i,j])  
  }
 timeblock = timeblocks(Y1,Y2,Y3,Y4,Y5)
 Nlag = timeblock$Nlag
 block = timeblock$block
 # For the timeblock created, run the model
 SAM("data/dataset2.csv","data/dataset3.csv",Nlag,block,prior=FALSE)
}

```

***

Overnight on 18/03, I ran the above chunk for ~16 hours. 35 model runs were 
completed before I stopped the script. 

Quick and dirty analysis of time taken for model runs vs number of years/blocks
showed that model runtime increased non-linearly (but not quite exponentially)
as the number of years/blocks increased. This was done by fitting trend lines in
Excel to the graphs of years/blocks vs runtime. Good R2 values of ~0.90 were 
seen for power fits (terribly non-rigorous assessment but just to get an idea)

Model outputs can be found at 
https://unsw-my.sharepoint.com/:f:/g/personal/z5293113_ad_unsw_edu_au/EgNrHWG4bLdOodEOl8gd1s0BHXXHy1CHLQ5XK3wNC7g3Dw?e=CsBhzc
to avoid the issue of large and possibly changing files being uploaded to
github.


***

# Model Comparison

Now that we have a selection of model outputs, we can compare how these performed
and hopefully make some comments on how far back to calculate lags and what effect
grouping months into time blocks has on model performance.

Having spoken to Manon, we want to try and rank each model by a quantile rank
method.

First we put all the available outputs into a dataframe

```{r}
# Find all outputs available
models = list.files(pattern = "SAM_posterior")
# Load them
for (i in 1:length(models)){
  load(models[i])
}
# Find all the model outputs we've loaded
models = objects(pattern = "SAM_posterior")

# Put these into a dataframe as it will be easier to work with
MODELS = data.frame(row.names=models)

for (i in 1:length(models)){
MODELS[i,1:11]=data.frame(t(sapply(get(models[i]),c)))
}
for (j in 6:11){
  MODELS[,j]=sapply(MODELS[,j],c)
}


# The metrics are as such
# Minimise: DIC, MAE, Q5, Q95, NMSE
# Maximise: R2
```

I am struggling to identify a way to assign ranks to the models for each metric
such that the ranks also differentiate between absolute model performance.

The below chunk highlights the issue with percentile ranks. Assume these 
are R2 values and therefore values closer to one are better.

Looking at the vector x, it is clear that the first 23 models have a poor
performance relative to R2 while the 24th model has a VERY good performance 
relative to the other models. 

However, assigning the percentile rank implies that 0.02, 0.03, 0.04 and 0.99
are to be assigned very high ranks while 0.01 has a very low rank. 

This doesn't capture how the models have performed at all. 0.02 isn't better than 
0.01 and 0.99 is WAY better than 0.04 - none of this is indicated in the ranks.

```{r}
# Create fake vector
x = c(rep(0.01,20),0.02,0.03,0.04,0.99)
# Calculate percentile rank
rank = percent_rank(signif(x,3))
# Print ranks to highlight issue
names(rank) = x
rank
```

However, I'll stick with this for now. 

```{r}
# Create a dataframe of ranks
RANK = MODELS
# We rank each metric, rounding before and after in an attempt to kind of group
# similarly performing models together 
RANK$DICrank = round(percent_rank(-1*signif(MODELS$DIC,3)),2)
RANK$R2rank = round(percent_rank(signif(MODELS$R2,3)),2)
RANK$MAErank = round(percent_rank(-1*signif(MODELS$MAE,3)),2)
RANK$NMSErank = round(percent_rank(-1*signif(MODELS$NMSE,3)),2)
RANK$Q5rank = round(percent_rank(-1*signif(MODELS$Q5,3)),2)
RANK$Q95rank = round(percent_rank(-1*signif(MODELS$Q95,3)),2)
# Remove the old rows
RANK = RANK[-(1:11)]
# Sum the ranks in a new column
RANK$sum = rowSums(RANK)
# Sort the dataframe by sum descending.
RANK = RANK[order(-RANK$sum),]
# Found datatable from https://rstudio.github.io/DT/010-style.html
# Here, we color each column with higher ranks being more green
brk <- quantile(RANK, probs = seq(.05, .95, .05), na.rm = TRUE)
clr <- {paste0("rgb(", round(seq(255, 40, length.out = length(brk) + 1), 0), ",255,", round(seq(255, 40, length.out = length(brk) + 1), 0), ")")}
x = datatable(RANK)
formatStyle(x,1:6, backgroundColor = styleInterval(brk, clr))

```

It would be nice to combine the above into a function - just sayin.

***

# Spring Precipitation

I've created a function called SpringBlock which hopefully creates timeblocks
in such a manner that we can investigate to what extent antecedent spring rain
influences NPP

```{r}
SpringBlock <- function(Nlag,Unique.years=TRUE){
  # Function that creates timeblocks where each year is split into spring
  # and non-spring blocks. Spring in Colorado is ~April,May,June
  # 
  # Inputs:
  # - Nlag = number of past years we want to consider
  # - Unique.years = boolean operator. If TRUE, each year has unique weights
  # for its spring and non-spring rainfall. If FALSE, all spring rain received
  # over the lag period is assigned the same weight, and similarly for non-spring
  # 
  # Outputs:
  # - Nlag = same as input. Included for consistency with timeblocks function
  # - block = a Nlag x 12 matrix of monthly weight identifiers
   
  # if we want each years to have unique weights
  if (Unique.years==TRUE){
    block = NULL
    for (i in seq(1,Nlag*2,by=2)){
      row = c(rep(i,3),rep(i+1,3),rep(i,6))
      block = c(block,row)}
    block = matrix(block,nrow=Nlag,ncol=12,byrow=TRUE)
    print(block)
  } else {
  # otherwise we just repeat the first year as many times as needed
      block = rep(c(rep(1,3),rep(2,3),rep(1,6)),Nlag)
      block = matrix(block,nrow=Nlag,ncol=12,byrow=TRUE)
  }
  lag = list("Nlag"=Nlag,"block"=block)
}
```

I ran this for 1 to 10 years and then evaluated our model for each block:
```{r, eval=FALSE}
source("SAMFunction.R")

for (i in 1:10){
  # Create the spring/nonspring timeblock
  timeblock=SpringBlock(i)
  Nlag = timeblock$Nlag
  block = timeblock$block
  # For the timeblock created, run the model
  SAM("data/dataset2.csv","data/dataset3.csv",Nlag,block,prior=FALSE)
}
```

I created the below script which finds all the output files from the model run 
and then plots them, grouped by length of considered lag and then colours them 
based on the season of the weight. This took forever. 
```{r}
library(ggplot2)
rm(list=ls())
# Find all outputs available
models = list.files(pattern = "2020-03-19")
# Load them
for (i in 1:length(models)){
  load(models[i])
}


# Find all the model outputs we've loaded
models = objects(pattern = "SAM_posterior")

# Put these into a dataframe as it will be easier to work with
MODELS = data.frame(row.names=models)

for (i in 1:length(models)){
  MODELS[i,1:11]=data.frame(t(sapply(get(models[i]),c)))
}
for (j in 6:11){
  MODELS[,j]=sapply(MODELS[,j],c)
}

# Put the model with 10 year lag to the end because that's so much nicer
MODELS[11,]=MODELS[2,]
MODELS = MODELS[-2,]
attr(MODELS,"row.names")[10]= c("SAM_posterior_10_20")

# Group the weights into seasons by replacing each 3 month block with its mean
# which is just the value for each of the months
uniWeights = matrix(0,nrow=nrow(MODELS),ncol=40)
for (i in 1:nrow(MODELS)){
  weights = MODELS$monthlyWeights[[i]]$mean
  k=0
  for (j in seq(1,length(weights),by=3)){
    k = k+1
    uniWeights[i,k] = mean(weights[j:j+2])
  }
}
# We now perform a sort of normalisation so that the total weight is equal to 
# the number of years. 
# for (i in 1:10){
#   uniWeights[i,] = uniWeights[i,]*i/sum(uniWeights[i,])
# }

# Make the final plotting dataframe
plotWeights = data.frame("Weights"=as.vector(t(uniWeights)),
                         "Block"=rep(1:40,10),
                         "Season"=rep(c("Oct-Dec","Jul-Sep","Apr-Jun","Jan-Mar"),
                                      100),
                         "Model"=rep(c("Lag1","Lag2","Lag3","Lag4","Lag5",
                                       "Lag6","Lag7","Lag8","Lag9","Lag10"),
                                     each=40))

# Assign levels so that it plots nicely
plotWeights$Season=factor(plotWeights$Season,
                          levels=c("Oct-Dec","Jul-Sep","Apr-Jun","Jan-Mar"))

plotWeights$Model=factor(plotWeights$Model,
                         levels=c("Lag1","Lag2","Lag3","Lag4","Lag5",
                                  "Lag6","Lag7","Lag8","Lag9","Lag10"))

# Remove rows where the weight is 0 for aesthetic reasons
plotWeights = plotWeights[plotWeights$Weights!=0,]

# Plot
plot1 <- ggplot(plotWeights,aes(x=Block,y=Weights,fill=Season)) +
  geom_bar(stat="identity", position=position_dodge()) +
  facet_grid(.~Model,scales = "free_x",switch = "x", space = "free_y")

last_plot()  

```

As can be seen in the graph, for all models, spring rainfall is usually 
relatively more important than the other seasons.



**To do:**
* **Produce a function that compares model outputs by quantile ranking the 
model performance metrics**
* **Create a function that produces a "block" that groups weight as "spring" rain 
and non-spring rain - *DONE***
* **Create a more generic SpringBlock function where you can specify the months of
spring.**
* **Create a function that, for a specific length of time N, creates an ensemble of
models where a model exists for every possible block of N years of observed data
that has been fed only those years of data and then assessed OOS against the other
blocks of N years. It will be interesting to model on eg. 1965-1975 with a lag of 
5 years and then see how model performance compares for 1950-1960 and 1980-1990**



